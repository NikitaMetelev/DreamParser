{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slh6oxraK-jS"
      },
      "source": [
        "# Парсинг DICE.COM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orEwnEoxLJV5"
      },
      "source": [
        "Никита Метелёв"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка среды, импорт библиотек"
      ],
      "metadata": {
        "id": "p3zRn7muXsgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инсталлируем необходимые пакеты и обеспечим возможность работы Selenium в Colab"
      ],
      "metadata": {
        "id": "bkF7COuHWy04"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt97lMZQniYG"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "apt-get update\n",
        "apt-get install chromium chromium-driver\n",
        "pip3 install selenium"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импортируем необходимые библиотеки:"
      ],
      "metadata": {
        "id": "KxSa93zlWlBk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "50xlG_gVH5UU"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import csv\n",
        "\n",
        "from datetime import date\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", ResourceWarning)\n",
        "warnings.simplefilter(\"ignore\", FutureWarning)\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Инициализируем переменные"
      ],
      "metadata": {
        "id": "oUMZtDzdX4N9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tlXBJ4W4Xetj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gnonNc_UH-TB"
      },
      "outputs": [],
      "source": [
        "headers = {\n",
        "    \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
        "    \"X-Is-Ajax-Request\": \"X-Is-Ajax-Request\",\n",
        "    \"X-Requested-With\": \"XMLHttpRequest\",\n",
        "    \"User-Agent\": (\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "                  \"(KHTML, like Gecko) Chrome/91.0.4472.106 Safari/537.36\")\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задаём параметры для корректной работы Selenium"
      ],
      "metadata": {
        "id": "ZY6CTpBbYjCd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p7GPNitPKdL4"
      },
      "outputs": [],
      "source": [
        "options = Options()\n",
        "options.add_argument(\"--headless\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "service = Service(\"chromedriver\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция определяет __дату публикации__ исходя из прошедшего времени относительно московского\n",
        "работает только для вакансий за последние 24 часа\n",
        "\n",
        "На вход получает строку типа:\n",
        "- _\"Posted 2 hours ago\"_\n",
        "- _\"Posted moments ago\"_\n",
        "\n",
        "Возвращает дату публикации вакансии"
      ],
      "metadata": {
        "id": "JrOyxKrKYyNC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "enFwuThuKdVX"
      },
      "outputs": [],
      "source": [
        "def dt_job(time_ago):\n",
        "  if time_ago.split()[1] == 'moments':\n",
        "    hours = -3\n",
        "  else:\n",
        "    hours = int(time_ago.split()[1]) - 3\n",
        "  date = (pd.datetime.now() - pd.DateOffset(hours=hours)).date()\n",
        "  return date"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем пустой список для ссылок на вакансии"
      ],
      "metadata": {
        "id": "QjL-VV7_cnvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_href = []"
      ],
      "metadata": {
        "id": "ZdBV1BvRcn_3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем первый датафрейм, куда внесем информацию со страницы поиска"
      ],
      "metadata": {
        "id": "DDA1D-_WcEBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем список для подробной информации по каждой вакансии"
      ],
      "metadata": {
        "id": "7OcnbhizdJc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_data = []"
      ],
      "metadata": {
        "id": "RL-DaY7DdKot"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ссылка на страницу поиска _dice.com_ с запросом:\n",
        "- junior data analyst OR scientist\n",
        "- только за последние 24 часа\n",
        "- 300 вакансий на странице\n",
        "\n",
        "Больше 150 вакансий за день не видел, обычно около 50.\n",
        "Листать не придется"
      ],
      "metadata": {
        "id": "TPWtdCN9NKIS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dkVK1noZKda0"
      },
      "outputs": [],
      "source": [
        "vpp = 300 # количество вакансий на одной странице\n",
        "dice_url = ('https://www.dice.com/jobs?q=junior%20'\n",
        "            'data%20analyst%20OR%20scientist&countryCode=US'\n",
        "            f'&radius=30&radiusUnit=mi&page=1&pageSize={vpp}&filters.'\n",
        "            'postedDate=ONE&language=en&eid=S2Q_')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Рабочий цикл"
      ],
      "metadata": {
        "id": "_T7otfhuOTRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С Selenium открываем страницу поиска"
      ],
      "metadata": {
        "id": "EIW1YvO0OZ4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver = webdriver.Chrome(service=service, options=options)\n",
        "driver.get(dice_url)\n",
        "driver.maximize_window()\n",
        "time.sleep(7)"
      ],
      "metadata": {
        "id": "Dq4rjr4V54ed"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Собираем ссылки на вакансии"
      ],
      "metadata": {
        "id": "92Qcp7LPOrmd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wldUhRg_LmGU"
      },
      "outputs": [],
      "source": [
        "for elem in driver.find_elements(By.XPATH,'//*[@class=\"card-title-link bold\"]'):\n",
        "    list_href.append(elem.get_attribute('href'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "По каждой вакансии достаем информацию со страницы поиска"
      ],
      "metadata": {
        "id": "q5JvQEJlPBUv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ackRPC_2LmIo"
      },
      "outputs": [],
      "source": [
        "df = []\n",
        "for i in range(1, len(list_href)+1):\n",
        "\n",
        "  job_post = (driver.\n",
        "              find_element\n",
        "              (By.XPATH,\n",
        "               '//*[@id=\"searchDisplay-div\"]/div[3]/dhi-search-'\n",
        "              f'cards-widget/div/dhi-search-card[{i}]').\n",
        "              text.splitlines()[0])\n",
        "\n",
        "  comp_loc = (driver.\n",
        "              find_element\n",
        "              (By.XPATH,\n",
        "                '//*[@id=\"searchDisplay-div\"]/div[3]/dhi-search-'\n",
        "              f'cards-widget/div/dhi-search-card[{i}]'\n",
        "                '/div/div[1]/div/div[2]/div[1]/div').\n",
        "              text.splitlines())\n",
        "\n",
        "  company = comp_loc[0]\n",
        "\n",
        "  if len(comp_loc) > 1:\n",
        "     location = comp_loc[1].removesuffix(', USA')\n",
        "  else:\n",
        "    location = None\n",
        "\n",
        "  working_conditions = (driver.\n",
        "                        find_element\n",
        "                        (By.XPATH,\n",
        "                         '//*[@id=\"searchDisplay-div\"]/div[3]'\n",
        "                        f'/dhi-search-cards-widget/div/dhi-search-card[{i}]'\n",
        "                         '/div/div[2]/div[1]').\n",
        "                        text.splitlines()[0])\n",
        "\n",
        "  posted = (driver.\n",
        "            find_element\n",
        "            (By.XPATH, '//*[@id=\"searchDisplay-div\"]/div[3]/dhi-search'\n",
        "            f'-cards-widget/div/dhi-search-card[{i}]/div/div[2]/div[1]').\n",
        "            text.splitlines()[1])\n",
        "\n",
        "  info_another = (driver.find_element\n",
        "                     (By.XPATH, '//*[@id=\"searchDisplay-div\"]/div[3]/dhi-'\n",
        "                     f'search-cards-widget/div/dhi-search-card[{i}]'\n",
        "                     '/div/div[2]/div[2]')\n",
        "                     .text.splitlines()[0])\n",
        "\n",
        "  df.append({'title' : job_post,\n",
        "            'company' : company,\n",
        "            'country' : 'USA',\n",
        "            'location' : location,\n",
        "            'date' : dt_job(posted),\n",
        "            'company_field' : None,\n",
        "            'job_type' : working_conditions,\n",
        "            'info_another' : info_another})\n",
        "driver.close()\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[6]"
      ],
      "metadata": {
        "id": "o4MIxtumDmKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237e01d9-da4a-4392-ea9e-22fdf1d2c640"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': 'Entry Level QC Analyst',\n",
              " 'company': 'Zachary Piper Solutions, LLC',\n",
              " 'country': 'USA',\n",
              " 'location': 'Baltimore, MD',\n",
              " 'date': datetime.date(2023, 6, 21),\n",
              " 'company_field': None,\n",
              " 'job_type': 'Full-time',\n",
              " 'info_another': 'Piper Companies is currently seeking an Entry Level QC Analyst for a biological manufacturing organization based in Baltimore, MD. Responsibilities for the Entry Level QC Analyst: Assist in performing routine analytical tests on raw materials, in-process samples, and finished products following established protocols and standard operating procedures (SOPs).Conduct qualitative and quantitative tests, including physical, chemical, and microbiological assays, to evaluate product quality and compli'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заходим в каждую вакансию и собираем:\n",
        "- полное описание,\n",
        "- хард скилы,\n",
        "- компенсацию"
      ],
      "metadata": {
        "id": "c1tXPWyLPbxA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1mvGW0IFLmL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b246b208-7966-4763-aca0-2fd61be3559b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n",
            "Saving\n"
          ]
        }
      ],
      "source": [
        "for url in list_href:\n",
        "    time.sleep(1)\n",
        "    # некоторые ссылки ведут на сторонние сайты, поэтому проверяем домен\n",
        "    # прежде чем продолжить\n",
        "    if url[:20] == 'https://www.dice.com':\n",
        "      req = requests.get(url=url, headers=headers)\n",
        "      soup = BeautifulSoup(req.text, \"lxml\")\n",
        "\n",
        "      skills = ''\n",
        "      for skill in soup.find_all(class_=\"skill-badge\"):\n",
        "          skills += skill.text + ', '\n",
        "      skills = skills.strip(', ')\n",
        "\n",
        "      dscr= soup.find('div', class_=\"mb-16 min-h-[300px]\").text\n",
        "\n",
        "      # зарплата указана не во всех вакансиях,\n",
        "      # сначала проверяю наличие информации\n",
        "      salary = None\n",
        "      salary_div = soup.find('div',\n",
        "                        class_='job-info order-4 col-span-2 mb-10 md:mb-0 '\n",
        "                        'sm:col-span-1 md:col-span-4 lg:col-span-5 lg:mb-0')\n",
        "\n",
        "      for element in salary_div:\n",
        "        if element.get('data-cy') == 'compensationText':\n",
        "          salary = (soup.find('div',\n",
        "                        class_='job-info order-4 col-span-2 mb-10 md:mb-0 sm:'\n",
        "                        'col-span-1 md:col-span-4 lg:col-span-5 lg:mb-0').\n",
        "                        find('p').\n",
        "                        text)\n",
        "    else:\n",
        "      skills = None\n",
        "      dscr = '-'\n",
        "      salary = None\n",
        "    data = {\n",
        "        'salary' : salary,\n",
        "        'source' : 'dice.com',\n",
        "        'link' : url,\n",
        "        'description' : dscr,\n",
        "        'skills' : skills\n",
        "    }\n",
        "    job_data.append(data)\n",
        "    print(\"Saving\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объединяем результаты и выгружаем в CSV"
      ],
      "metadata": {
        "id": "j0fifkyIpFkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'dice_jobs {date.today()}', mode=\"w\", encoding='utf-8') as w_file:\n",
        "    names = ['title',\n",
        "           'company',\n",
        "           'country',\n",
        "           'location',\n",
        "           'salary',\n",
        "           'source',\n",
        "           'link',\n",
        "           'date',\n",
        "           'company_field',\n",
        "           'description',\n",
        "           'skills',\n",
        "           'job_type']\n",
        "    file_writer = csv.DictWriter(w_file, delimiter = \",\",\n",
        "                                 lineterminator=\"\\r\", fieldnames=names)\n",
        "    file_writer.writeheader()\n",
        "    for i in range(len(list_href)):\n",
        "      row = job_data[i] | df[i]\n",
        "      if row['description'] == '-':\n",
        "        row['description'] = row['info_another']\n",
        "      del row['info_another']\n",
        "      file_writer.writerow(row)"
      ],
      "metadata": {
        "id": "L0e8gCm73wLE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В итоге получили csv файл с вакансиями за последные сутки с сайта dice.com для новичков в Data Science"
      ],
      "metadata": {
        "id": "rzfUG0JU_-kD"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}